{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scoring.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Using importance_score and model_importance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from variable_importance_testing.scoring import importance_score, model_importance_score\n",
    "\n",
    "# Generate dummy data\n",
    "np.random.seed(42)\n",
    "X = np.random.randint(2, size=(100, 5))\n",
    "y = X[:, 0]  # Target is only 1 if the first variable is 1\n",
    "\n",
    "true_importances = [1, 0, 0, 0, 0]\n",
    "\n",
    "model = Lasso(alpha=0.1).fit(X, y)\n",
    "\n",
    "# Calculate model importance score\n",
    "pred_importances = model.coef_\n",
    "print(importance_score(pred_importances, true_importances))\n",
    "\n",
    "# Alternatively, use model_importance_score directly\n",
    "# (Because LASSO's variable importance attribute is 'coef_', \n",
    "# the model_importance_score function will automatically get it\n",
    "# without needing to pass in an importance_attr)\n",
    "print(model_importance_score(model, true_importances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Using importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model_top_n Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Training R^2 Score: 0.8397384552949719\n",
      "Test R^2 Score: 0.8348324896407362\n",
      "_model_top_n Score: 1.0\n",
      "{'times': {'model_top_n': '00:00:00'}, 'training_r2': 0.8397384552949719, 'test_r2': 0.8348324896407362, '_model_top_n_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from variable_importance_testing.scoring import importance_scores\n",
    "\n",
    "# Generate dummy data\n",
    "np.random.seed(42)\n",
    "X = np.random.randint(2, size=(100, 5))\n",
    "y = X[:, 0]  # Target is only 1 if the first variable is 1\n",
    "\n",
    "# Define true importances\n",
    "true_importances = [1, 0, 0, 0, 0]\n",
    "\n",
    "# Initialize the model\n",
    "model = Lasso(alpha=0.1)\n",
    "\n",
    "# Call the importance_scores function\n",
    "results = importance_scores(model=model, \n",
    "                            X=X, \n",
    "                            y=y, \n",
    "                            true_importances=true_importances, \n",
    "                            test_size=0.3, \n",
    "                            verbose=True)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Using importance_scores with cross-validate setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_top_n Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Starting model_pearson Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Training R^2 Score: 0.8397384552949719\n",
      "CV R^2 Score: 0.8340964096186465\n",
      "Test R^2 Score: 0.8348324896407362\n",
      "true_importances_model_top_n Score: 1.0\n",
      "true_importances_model_pearson Score: 1.0\n",
      "bad_importances_model_top_n Score: 0.0\n",
      "bad_importances_model_pearson Score: -0.25\n",
      "\n",
      "RESULTS:\n",
      "times: {'cv': '00:00:00', 'model_top_n': '00:00:00', 'model_pearson': '00:00:00'}\n",
      "model: Lasso(alpha=0.1, max_iter=10000)\n",
      "params: {'max_iter': 10000, 'alpha': 0.1}\n",
      "cv_r2: 0.8340964096186465\n",
      "training_r2: 0.8397384552949719\n",
      "test_r2: 0.8348324896407362\n",
      "true_importances_model_top_n_score: 1.0\n",
      "bad_importances_model_top_n_score: 0.0\n",
      "true_importances_model_pearson_score: 1.0\n",
      "bad_importances_model_pearson_score: -0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from variable_importance_testing.scoring import model_importance_score, importance_scores\n",
    "\n",
    "# Generate dummy data\n",
    "np.random.seed(42)\n",
    "X = np.random.randint(2, size=(100, 5))\n",
    "y = X[:, 0]  # Target is only 1 if the first variable is 1\n",
    "\n",
    "# Initialize the model and make a parameter grid for CV\n",
    "model = Lasso()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 10],\n",
    "    'max_iter': [1000, 10000],\n",
    "}\n",
    "\n",
    "# Initialize CV object\n",
    "cv = RandomizedSearchCV(model, param_grid, cv=5, scoring='r2', verbose=0, n_iter=5)\n",
    "\n",
    "# Define a custom score function\n",
    "def model_importance_pearsonr(model, true_importances, importance_attr, ranked, **kwargs):\n",
    "    return model_importance_score(model, true_importances, importance_attr, score=pearsonr, ranked=ranked)\n",
    "# score functions can currently only accept the following keyword arguments:\n",
    "# model, X, y, true_importances, importance_attr, and ranked\n",
    "\n",
    "# (they don't have to accept all of the above arguments, but they\n",
    "# cannot accept arguments aside from the above unless they have default parameters)\n",
    "\n",
    "# Passing in two score functions\n",
    "score_functions = {\n",
    "    \"model_top_n\": model_importance_score, \n",
    "    \"model_pearson\": model_importance_pearsonr\n",
    "    }\n",
    "\n",
    "# Passing in two ground truths\n",
    "true_importances = {\"true_importances\": [1, 0, 0, 0, 0], \"bad_importances\": [0, 0, 0, 0, 1]}\n",
    "\n",
    "# Call the importance_scores function\n",
    "results = importance_scores(model=cv, \n",
    "                            X=X, \n",
    "                            y=y, \n",
    "                            true_importances=true_importances, \n",
    "                            test_size=0.3, \n",
    "                            score_functions=score_functions, \n",
    "                            cross_validate=True,\n",
    "                            verbose=True)\n",
    "\n",
    "print(\"\\nRESULTS:\")\n",
    "for result in results:\n",
    "    print(f\"{result}: {results[result]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Using importance_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Importance Testing...\n",
      "Setup Done!\n",
      "Starting Testing...\n",
      "\n",
      "***###dataset1:###***\n",
      "\n",
      "***Scoring Lasso...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Training R^2 Score: 0.8397384552949719\n",
      "CV R^2 Score: 0.8272277663672328\n",
      "Test R^2 Score: 0.8348324896407362\n",
      "_model_importance Score: 1.0\n",
      "\n",
      "***Scoring XGBoost...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'xgboost.sklearn.XGBRegressor'>\n",
      "Training R^2 Score: 0.9999999482929727\n",
      "CV R^2 Score: 0.9999999130962699\n",
      "Test R^2 Score: 0.9999999467101103\n",
      "_model_importance Score: 1.0\n",
      "\n",
      "***###dataset2:###***\n",
      "\n",
      "***Scoring Lasso...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Training R^2 Score: 0.84\n",
      "CV R^2 Score: 0.82553729147441\n",
      "Test R^2 Score: 0.84\n",
      "_model_importance Score: 1.0\n",
      "\n",
      "***Scoring XGBoost...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'xgboost.sklearn.XGBRegressor'>\n",
      "Training R^2 Score: 0.8582878864743275\n",
      "CV R^2 Score: 0.8432793254185875\n",
      "Test R^2 Score: 0.8582878864743275\n",
      "_model_importance Score: 1.0\n",
      "All Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from variable_importance_testing.dgp import DataGenerator\n",
    "from variable_importance_testing.scoring import importance_testing\n",
    "\n",
    "# Define parameter grids\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.1, 1, 10],\n",
    "    'max_iter': [1000, 10000],\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 300],\n",
    "}\n",
    "\n",
    "# Generate dummy datasets\n",
    "np.random.seed(42)\n",
    "X = np.random.randint(2, size=(100, 5))\n",
    "y1 = np.expand_dims(X[:, 0].T, axis=1)\n",
    "y2 = np.expand_dims(X[:, 1].T, axis=1)\n",
    "\n",
    "# Two datasets, one with y = feature 1 and the other with y = feature 2\n",
    "# The importance_testing function treats the last column as the target\n",
    "datasets = {\"dataset1\": np.concatenate((X, y1), axis=1), \"dataset2\": np.concatenate((X, y2), axis=1)}\n",
    "true_importances = {\"dataset1\": [1, 0, 0, 0, 0], \"dataset2\": [0, 1, 0, 0, 0]}\n",
    "\n",
    "# Define models and parameters\n",
    "models = {\"Lasso\": Lasso, \"XGBoost\": XGBRegressor}\n",
    "param_grids = {\"Lasso\": param_grid_lasso, \"XGBoost\": param_grid_xgb}\n",
    "\n",
    "# Make the CV do 3 iterations of RandomizedSearchCV for the LASSO model\n",
    "# (It will automatically do 10% of the parameter space for the non-specified models)\n",
    "n_iters = {\"Lasso\": 3}\n",
    "\n",
    "# Importance attributes for each model \n",
    "# (technically not necessary for these two importance attributes)\n",
    "importance_attrs = {\"Lasso\": 'coef_', \"XGBoost\": 'feature_importances_'}\n",
    "\n",
    "# Run importance testing\n",
    "importance_testing(\n",
    "    models=models,\n",
    "    param_grids=param_grids,\n",
    "    datasets=datasets,\n",
    "    true_importances=true_importances,\n",
    "    importance_attrs=importance_attrs,\n",
    "    save_results=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Using importance_testing with automated pipelining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Importance Testing...\n",
      "Setup Done!\n",
      "Starting Testing...\n",
      "\n",
      "***###dataset:###***\n",
      "\n",
      "***Scoring Lasso...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Training R^2 Score: 0.8397384552949719\n",
      "CV R^2 Score: 0.8272277663672328\n",
      "Test R^2 Score: 0.8348324896407362\n",
      "_model_importance Score: 1.0\n",
      "\n",
      "***Scoring FastSparse...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'variable_importance_testing.fastsparsewrap.FastSparseSklearn'>\n",
      "Training R^2 Score: 1.0\n",
      "CV R^2 Score: 1.0\n",
      "Test R^2 Score: 1.0\n",
      "_model_importance Score: 1.0\n",
      "\n",
      "***Scoring XGBoost...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'xgboost.sklearn.XGBRegressor'>\n",
      "Training R^2 Score: 0.8582754142957817\n",
      "CV R^2 Score: 0.8447753195059513\n",
      "Test R^2 Score: 0.8539763522239084\n",
      "_model_importance Score: 1.0\n",
      "\n",
      "***Scoring Lasso + XGBoost...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'variable_importance_testing.pipelining.VI_Pipeline'>\n",
      "Training R^2 Score: 0.8582754142957817\n",
      "CV R^2 Score: 0.8447753195059513\n",
      "Test R^2 Score: 0.8539763522239084\n",
      "_model_importance Score: 1.0\n",
      "\n",
      "***Scoring FastSparse + XGBoost...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'variable_importance_testing.pipelining.VI_Pipeline'>\n",
      "Training R^2 Score: 0.8582754142957817\n",
      "CV R^2 Score: 0.8447753195059513\n",
      "Test R^2 Score: 0.8539763522239084\n",
      "_model_importance Score: 1.0\n",
      "All Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from variable_importance_testing.dgp import DataGenerator\n",
    "from variable_importance_testing.fastsparsewrap import FastSparseSklearn\n",
    "from variable_importance_testing.scoring import importance_testing\n",
    "\n",
    "# Define parameter grids\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.1, 1, 10],\n",
    "    'max_iter': [1000, 10000],\n",
    "}\n",
    "\n",
    "param_grid_fastsparse = {\n",
    "    \"max_support_size\": [5, 10],\n",
    "    \"atol\": [1e-8, 1e-7],\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 300],\n",
    "}\n",
    "\n",
    "param_grids = {\"Lasso\": param_grid_lasso, \"FastSparse\": param_grid_fastsparse, \"XGBoost\": param_grid_xgb}\n",
    "\n",
    "# Generate dummy dataset\n",
    "np.random.seed(42)\n",
    "X = np.random.randint(2, size=(100, 5))\n",
    "y = np.expand_dims(X[:, 0].T, axis=1)\n",
    "\n",
    "# The importance_testing function treats the last column as the target\n",
    "datasets = {\"dataset\": np.concatenate((X, y), axis=1)}\n",
    "true_importances = {\"dataset\": [1, 0, 0, 0, 0], }\n",
    "\n",
    "# Define models and parameters \n",
    "# if using trimming steps, you don't have to put predictors that are also trimming steps in models\n",
    "# BUT, if you want any final predictors to be evaluated on their own you must put them in models\n",
    "\n",
    "# the testing loop will automatically add lasso and fastsparse if they \n",
    "# aren't present in models, so including them in models doesn't change anything,\n",
    "# but it won't test XGBoost by itself unless it's included in models\n",
    "models = {\"Lasso\": Lasso, \"FastSparse\": FastSparseSklearn, \"XGBoost\": XGBRegressor} \n",
    "\n",
    "# Importance attributes for each model \n",
    "# (technically not necessary for these two importance attributes)\n",
    "importance_attrs = {\"Lasso\": 'coef_', \"FastSparse\": 'coef_', \"XGBoost\": 'feature_importances_'}\n",
    "\n",
    "# Make the CV do 4 iterations of RandomizedSearchCV for the XGBoost model\n",
    "# (This number also applies to every pipeline made with XGBoost as the final predictor)\n",
    "n_iters= {\"XGBoost\": 4}\n",
    "\n",
    "# Define trimming steps and final predictors\n",
    "trimming_steps = {\"Lasso\": Lasso, \"FastSparse\": FastSparseSklearn}\n",
    "final_predictors = {\"XGBoost\": XGBRegressor,}\n",
    "\n",
    "# Run importance testing\n",
    "importance_testing(\n",
    "    models=models,\n",
    "    param_grids=param_grids,\n",
    "    datasets=datasets,\n",
    "    true_importances=true_importances,\n",
    "    importance_attrs=importance_attrs,\n",
    "    trimming_steps=trimming_steps,\n",
    "    final_predictors=final_predictors,\n",
    "    save_results=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, first every model in models was tested individually, and then every combination of trimming step with final predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that the two-step pipelines built in this testing loop use the already cross-validated trimming steps as the first step in the pipeline and only cross-validate the final prediction step when testing the pipelines.\n",
    "\n",
    "Example: Lasso by itself is tested first in the loop. Once the cross-validation is finished, the loop takes the best parameters and constructs n \"optimal\" Lasso objects (where n is the number of final predictors). It then makes each new Lasso object the trimming step in a pipeline with a different final predictor and adds the pipeline to the testing queue with a param grid equivalent to the param grid passed in for the respective final predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dgp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6  7  8  9    target\n",
      "0  0  1  0  0  0  0  0  0  1  0 -0.861353\n",
      "1  0  1  1  0  0  1  1  1  1  0 -0.861353\n",
      "2  0  1  1  0  0  1  0  1  1  0 -0.861353\n",
      "3  1  1  0  0  0  1  0  1  1  0  0.138647\n",
      "4  0  1  0  0  0  1  1  1  1  0 -0.861353\n",
      "[1, 0.8613531161467861, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from variable_importance_testing.dgp import DataGenerator\n",
    "\n",
    "# Initialize the DataGenerator\n",
    "dgp = DataGenerator(\n",
    "    num_cols=10,\n",
    "    num_rows=10,\n",
    "    # to produce a 10x10 dataset (not including the target)\n",
    "\n",
    "    num_important=2, \n",
    "    # the first 2 features will affect the target\n",
    ")\n",
    "\n",
    "# Generate a dataset\n",
    "data = dgp.generate_data()\n",
    "\n",
    "print(data.head())\n",
    "print(dgp.importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable 0 has an effect size of 1 while variable 1 has an effect size of ~0.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Tweaking Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2  3  4  5  6  7  8  9       target\n",
      "0  1  1  0  0  1  1  1  0  0  0  9103.289920\n",
      "1  1  1  0  0  1  1  0  0  0  0  9101.330639\n",
      "2  1  1  0  1  0  1  0  1  1  0  9103.515903\n",
      "3  1  1  0  1  0  1  1  1  1  0  9101.549078\n",
      "4  0  1  0  0  1  1  0  1  1  1  8899.427308\n",
      "[100, 2.0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Frequency of feature 0: 615\n",
      "Frequency of feature 1: 1000\n",
      "Frequency of feature 2: 0\n",
      "Frequency of feature 3: 514\n",
      "Frequency of feature 4: 486\n",
      "Frequency of feature 5: 541\n",
      "Frequency of feature 6: 375\n",
      "Frequency of feature 7: 736\n",
      "Frequency of feature 8: 547\n",
      "Frequency of feature 9: 391\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from variable_importance_testing.dgp import DataGenerator\n",
    "\n",
    "dgp = DataGenerator(\n",
    "    num_cols=10,\n",
    "    num_rows=1000,\n",
    "    # to produce a 1000x10 dataset (not including the target)\n",
    "\n",
    "    num_important=3, \n",
    "    # the first 3 features will affect the target\n",
    "\n",
    "    frequencies={1: 1, 2: 0, 3: 0.5}, \n",
    "    # make feature 1 always be 1, feature 2 always be 0,\n",
    "    # and feature 3 be 1 50% of the time\n",
    "\n",
    "    effects={0: (lambda x: 100 if x == 1 else -100)}, \n",
    "    # make feature 0 add either 100 or -100 to the target\n",
    "    # depending on its value\n",
    "\n",
    "    num_interaction_terms=2, \n",
    "    correlation_scale=0.5, \n",
    "    correlation_distribution='normal', \n",
    "    # the last 2 features will each be correlated with\n",
    "    # one of the important features, and the amount of\n",
    "    # correlation will be chosen from a normal distribution\n",
    "    # with mean of 0 and standard deviation equal to 0.5\n",
    "\n",
    "    interactions={4: (3, -1)},\n",
    "    # add feature 4 as a third interaction term\n",
    "    # with perfect negative correlation with feature 3\n",
    "\n",
    "    intercept=9000, \n",
    "    # shift the values of target up by 9000\n",
    "\n",
    "    noise_distribution='normal',\n",
    "    noise_scale=0.01\n",
    "    # add noise chosen from a normal distribution with\n",
    "    # mean of 0 and standard deviation equal to 0.01 * the maximum \n",
    "    # absolute value of the target (pre-noise and pre-intercept)\n",
    "    # (in this case it'll be about 0.01* 100 because we set\n",
    "    # the effect of 0 to be so large)\n",
    ")\n",
    "\n",
    "# Generate a dataset\n",
    "data = dgp.generate_data()\n",
    "\n",
    "print(data.head())\n",
    "print(dgp.importances)\n",
    "\n",
    "for feature in data.columns:\n",
    "    if feature != 'target':\n",
    "        print(f\"Frequency of feature {feature}: {sum(data[feature])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the target is approximately 2* 100 lower in rows where feature 0 is 0.\n",
    "\n",
    "Further, feature 1 is 1 100% of the time and feature 2 is 1 0% of the time.\n",
    "\n",
    "Feature 3 is 1 about half of the time, and feature 4 is 1 every time that feature 3 is 0.\n",
    "\n",
    "The target is shifted up by 9000, and has some noise around an order of magnitude of 0.01 * 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using importance_testing and the DGP Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Importance Testing...\n",
      "Setup Done!\n",
      "Starting Testing...\n",
      "\n",
      "***###Toy:###***\n",
      "\n",
      "***Scoring Lasso...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:00\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'sklearn.linear_model._coordinate_descent.Lasso'>\n",
      "Training R^2 Score: 0.0\n",
      "CV R^2 Score: -0.04069548897873898\n",
      "Test R^2 Score: -0.005900991071757566\n",
      "constant_model_importance Score: 0.75\n",
      "scaled_model_importance Score: 0.75\n",
      "\n",
      "***Scoring XGBoost...***\n",
      "Starting Cross-Validation...\n",
      "Finished Cross-Validating in 00:00:01\n",
      "Starting model_importance Scoring...\n",
      "Finished Scoring in 00:00:00\n",
      "Scores For <class 'xgboost.sklearn.XGBRegressor'>\n",
      "Training R^2 Score: 0.9900442228492309\n",
      "CV R^2 Score: 0.784292279752136\n",
      "Test R^2 Score: 0.7793862520982247\n",
      "constant_model_importance Score: 0.5\n",
      "scaled_model_importance Score: 0.5\n",
      "All Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from variable_importance_testing.dgp import DataGenerator\n",
    "from variable_importance_testing.scoring import importance_testing\n",
    "\n",
    "# Define parameter grids\n",
    "param_grid_lasso = {\n",
    "    'alpha': [0.1, 1, 10],\n",
    "    'max_iter': [1000, 10000],\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'n_estimators': [100, 300],\n",
    "}\n",
    "\n",
    "# Generate synthetic datasets\n",
    "\n",
    "dgps = {\"Toy\": DataGenerator(num_cols=100, num_rows=100, num_important=10)}\n",
    "datasets = {name: dgp.generate_data() for name, dgp in dgps.items()}\n",
    "true_importances = {name: dgps[name].bucket_importances for name in dgps.keys()}\n",
    "\n",
    "# Define models and parameters\n",
    "models = {\"Lasso\": Lasso, \"XGBoost\": XGBRegressor}\n",
    "param_grids = {\"Lasso\": param_grid_lasso,  \"XGBoost\": param_grid_xgb}\n",
    "importance_attrs = {\"Lasso\": 'coef_', \"XGBoost\": 'feature_importances_'}\n",
    "\n",
    "# Run importance testing\n",
    "importance_testing(\n",
    "    models=models,\n",
    "    param_grids=param_grids,\n",
    "    datasets=datasets,\n",
    "    true_importances=true_importances,\n",
    "    importance_attrs=importance_attrs,\n",
    "    save_results=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Complex Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from variable_importance_testing.dgp import DataGenerator\n",
    "from variable_importance_testing.fastsparsewrap import FastSparseSklearn\n",
    "from variable_importance_testing.scoring import importance_score, model_importance_score, importance_testing\n",
    "from variable_importance_testing.cmr import CMR\n",
    "from variable_importance_testing.loco import LOCOImportance\n",
    "from variable_importance_testing.mr import MRImportance\n",
    "\n",
    "nrows = None\n",
    "results_folder = None\n",
    "\n",
    "print(\"Starting...\")\n",
    "\n",
    "###Parameter Grids###\n",
    "param_grid_lasso = {\n",
    "    'alpha': [1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1, 5, 10, 50, 100], \n",
    "    'max_iter': [1000, 2500, 5000, 10000, 25000, 500000, 1000000],  \n",
    "    'tol': [1e-4, 1e-3, 1e-2, 1e-1], \n",
    "}\n",
    "\n",
    "param_grid_fastsparse = {\n",
    "    \"max_support_size\": [5, 10, 15],\n",
    "    \"atol\": [1e-9, 1e-8, 1e-7, 1e-6, 1e-5],\n",
    "    \"lambda_0\": [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1],\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1], \n",
    "    'n_estimators': [100, 300, 500], \n",
    "    'max_depth': [3, 5, 7], \n",
    "    'min_child_weight': [1, 3, 5, 7], \n",
    "    'gamma': [0.1, 0.2, 0.3],  \n",
    "    'subsample': [0.8, 1.0],  \n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],  \n",
    "    'reg_lambda': [1, 1.5, 2],  \n",
    "    'reg_alpha': [0, 0.1, 0.5, 1], \n",
    "}\n",
    "\n",
    "param_grid_xgb_pipeline = {\n",
    "    'prediction__learning_rate': [0.01, 0.05, 0.1], \n",
    "    'prediction__n_estimators': [100, 300, 500],  \n",
    "    'prediction__max_depth': [3, 5, 7], \n",
    "    'prediction__min_child_weight': [1, 3, 5, 7],  \n",
    "    'prediction__gamma': [0.1, 0.2, 0.3], \n",
    "    'prediction__subsample': [0.8, 1.0], \n",
    "    'prediction__colsample_bytree': [0.6, 0.8, 1.0], \n",
    "    'prediction__reg_lambda': [1, 1.5, 2], \n",
    "    'prediction__reg_alpha': [0, 0.1, 0.5, 1], \n",
    "}\n",
    "\n",
    "###DATA###\n",
    "\n",
    "# Import outside dataset\n",
    "small_input_df = pd.read_table('test_files/small_dataset/Input.txt', header=None, low_memory=False, nrows=nrows)\n",
    "small_pheno_df = pd.read_table('test_files/small_dataset/Pheno.txt', header=None, nrows=nrows).drop(columns=0, axis=1).reset_index(drop=True)\n",
    "small_test_SNP_metadata_df = pd.read_csv('test_files/small_dataset/Test.SNP.metadata.csv')\n",
    "\n",
    "small_input_df['target'] = small_pheno_df.iloc[:, 0]\n",
    "small_dataset_importances = small_test_SNP_metadata_df[\"EffectSize\"]\n",
    "\n",
    "# DGPs\n",
    "dgps = {\n",
    "    \"Toy\": DataGenerator(\n",
    "        num_cols=100, num_rows=100, num_important=10, \n",
    "        num_interaction_terms=0, effects='linear', \n",
    "        noise_distribution='normal', noise_scale=0.1),\n",
    "    \"Slightly More Challening\": DataGenerator(\n",
    "        num_cols=100, num_rows=100, num_important=10, num_interaction_terms=20, effects='all', \n",
    "        correlation_scale=1.5, correlation_distribution='normal', \n",
    "        intercept=10, noise_distribution='normal', noise_scale=0.3),\n",
    "    \"High_Dimensionality\": DataGenerator(\n",
    "        num_cols=10000, num_rows=100, num_important=10, num_interaction_terms=20, effects='all', \n",
    "        correlation_scale=1, correlation_distribution='normal', \n",
    "        intercept=0, noise_distribution='normal', noise_scale=0.1),\n",
    "    \"High_Correlation\": DataGenerator(\n",
    "        num_cols=1000, num_rows=1000, num_important=10, num_interaction_terms=200, effects='all', \n",
    "        correlation_scale=0.95, correlation_distribution='uniform', \n",
    "        intercept=0, noise_distribution='normal', noise_scale=0.1),\n",
    "    \"High_Noise\": DataGenerator(\n",
    "        num_cols=1000, num_rows=1000, num_important=10, num_interaction_terms=50, effects='all', \n",
    "        correlation_scale=1, correlation_distribution='normal', \n",
    "        intercept=0, noise_distribution='uniform', noise_scale=0.5),\n",
    "    \"All Three\": DataGenerator(\n",
    "        num_cols=10000, num_rows=100, num_important=10, num_interaction_terms=200, effects='all', \n",
    "        correlation_scale=0.95, correlation_distribution='uniform', \n",
    "        intercept=0, noise_distribution='uniform', noise_scale=0.5),\n",
    "}\n",
    "\n",
    "# Generate Datasets \n",
    "datasets = {name: dgp.generate_data() for name, dgp in dgps.items()}\n",
    "true_importances = {name: dgps[name].importances for name in dgps.keys()}\n",
    "\n",
    "# Integrate outside data\n",
    "datasets[\"Small_Real_World\"] = small_input_df\n",
    "true_importances[\"Small_Real_World\"] = {\"constant\": small_dataset_importances}\n",
    "\n",
    "print(\"Datasets Generated...\")\n",
    "\n",
    "# Scoring methods\n",
    "def model_importance_spearmanr(model, true_importances, importance_attr, ranked=False, **kwargs):\n",
    "    return model_importance_score(model, true_importances, importance_attr, score=spearmanr, scramble=True, ranked=ranked)\n",
    "\n",
    "def model_importance_pearsonr(model, true_importances, importance_attr, ranked=False, **kwargs):\n",
    "    return model_importance_score(model, true_importances, importance_attr, score=pearsonr, ranked=ranked)\n",
    "\n",
    "def mr_importance(X, y, model, true_importances, score_func='r2', ranked=False, **kwargs):\n",
    "    mr = MRImportance(X, y, score_func, model)\n",
    "    return importance_score(mr.get_importance(), true_importances, ranked=ranked)\n",
    "\n",
    "def cmr_importance(X, y, model, true_importances, error_func=mean_squared_error, ranked=False, **kwargs):\n",
    "    cmr = CMR(X, y, error_func, model)\n",
    "    return importance_score(cmr.importance_all(), true_importances, ranked=ranked)\n",
    "\n",
    "def loco_importance(X, y, model, true_importances, score_func='r2', cv=5, ranked=False, **kwargs):\n",
    "    loco = LOCOImportance(X, y, score_func, model, cv=5)\n",
    "    return importance_score(loco.get_importance(), true_importances, ranked=ranked)\n",
    "\n",
    "score_functions = {\n",
    "    \"model_importance_top_n\": model_importance_score,\n",
    "    \"model_importance_spearmanr\": model_importance_spearmanr,\n",
    "    \"model_importance_pearsonr\": model_importance_pearsonr,\n",
    "    \"mr_importance\": mr_importance,\n",
    "    \"cmr_importance\": cmr_importance,\n",
    "    \"loco_importance\": loco_importance,\n",
    "}\n",
    "\n",
    "# Set up testing loop\n",
    "models = {\"LASSO\": Lasso, \"FastSparse\": FastSparseSklearn}\n",
    "param_grids = {\"LASSO\": param_grid_lasso, \"FastSparse\": param_grid_fastsparse, \"XGBoost\": param_grid_xgb}\n",
    "importance_attrs = {\"LASSO\": 'coef_', \"FastSparse\": 'coef_', \"XGBoost\": 'feature_importances_'}\n",
    "n_iters= {\"LASSO\": 300, \"FastSparse\": 100, \"XGBoost\": 2000}\n",
    "\n",
    "trimming_steps = {\"LASSO\": Lasso, \"FastSparse\": FastSparseSklearn,}\n",
    "final_predictors = {\"XGBoost\": XGBRegressor,}\n",
    "\n",
    "print(\"Parameters Initialized...\")\n",
    "\n",
    "importance_testing(\n",
    "    models, param_grids, datasets, true_importances, \n",
    "    score_functions=score_functions, importance_attrs=importance_attrs, \n",
    "    trimming_steps=trimming_steps, final_predictors=final_predictors,\n",
    "    n_iters=n_iters, ranked=True, \n",
    "    save_results=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
