{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "class DataGenerator:\n",
    "    EFFECT_SCALE_RANGE = 5\n",
    "    EFFECT_EXPONENT_RANGE = 5\n",
    "\n",
    "    all_functions = [\n",
    "        (lambda x, sign, c, n, i: sign * c * x * (1 / (DataGenerator.EFFECT_SCALE_RANGE))),\n",
    "        (lambda x, sign, c, n, i: sign * ((c * x) ** n) * (1 / (DataGenerator.EFFECT_SCALE_RANGE ** DataGenerator.EFFECT_EXPONENT_RANGE))),\n",
    "        (lambda x, sign, c, n, i: sign * ((c * x) ** (1/(n + 1)))),\n",
    "        (lambda x, sign, c, n, i: sign * math.log(abs(c) * x + 1, n + 1)),\n",
    "        (lambda x, sign, c, n, i: sign * (x and i)),\n",
    "        (lambda x, sign, c, n, i: sign * (x or i)),\n",
    "        (lambda x, sign, c, n, i: sign * (x ^ i))\n",
    "        ]\n",
    "\n",
    "    def __init__(self, \n",
    "                 num_cols=10, \n",
    "                 num_rows=10, \n",
    "                 num_important=1, \n",
    "                 num_interaction_terms=None, \n",
    "                 interaction_type='all', \n",
    "                 monotonic=False,\n",
    "                 importance_ranking=\"scaled\", \n",
    "                 effects=None, \n",
    "                 frequencies={}, \n",
    "                 correlation_scale=0.9, \n",
    "                 correlation_distribution='normal', \n",
    "                 target='target', \n",
    "                 intercept=0, \n",
    "                 noise_distribution='normal', \n",
    "                 noise_scale=0, \n",
    "                 rng=None):\n",
    "        \n",
    "        # Record initialization params\n",
    "        self.num_cols = num_cols\n",
    "        self.num_rows = num_rows\n",
    "        self.num_important = num_important\n",
    "        self.num_interaction_terms = num_interaction_terms if num_interaction_terms is not None else self.num_important\n",
    "        self.interaction_type = interaction_type\n",
    "        self.monotonic = monotonic\n",
    "        self.importance_ranking = importance_ranking\n",
    "        self.effects = effects\n",
    "        self.frequencies = frequencies\n",
    "        self.correlation_scale = correlation_scale\n",
    "        self.correlation_distribution = correlation_distribution\n",
    "        self.target = target\n",
    "        self.intercept = intercept\n",
    "        self.noise_distribution = noise_distribution\n",
    "        self.noise_scale = noise_scale\n",
    "\n",
    "        # Generate default parameters\n",
    "        self.rng = np.random.default_rng() if rng is None else rng\n",
    "        self.cols = range(num_cols)\n",
    "        self.important_variables = self.cols[:num_important]\n",
    "        self.interaction_terms = self.cols[-self.num_interaction_terms:]\n",
    "    \n",
    "        for col in self.cols:\n",
    "            if col not in frequencies.keys():\n",
    "                frequencies[col] = self.rng.random()\n",
    "        \n",
    "        # Choose functions according to interaction type\n",
    "        self.functions = DataGenerator.all_functions\n",
    "        \n",
    "        if interaction_type == 'all':\n",
    "            self.functions = DataGenerator.all_functions\n",
    "        elif interaction_type =='linear':\n",
    "            self.functions = DataGenerator.all_functions[0:1]\n",
    "        else:\n",
    "            raise ValueError(\"interaction_type must be either 'all' or 'linear'\")\n",
    "\n",
    "        self.interactions = self.generate_interactions()\n",
    "\n",
    "        # Check if effects is a string, if so change target functions\n",
    "        self.target_functions = DataGenerator.all_functions\n",
    "\n",
    "        if effects == 'all':\n",
    "            self.target_functions = DataGenerator.all_functions\n",
    "        elif effects == 'linear':\n",
    "            self.target_functions = DataGenerator.all_functions[0:1]\n",
    "        elif effects == 'constant':\n",
    "            self.effects = [(lambda x: x) if i in self.important_variables else (lambda x: 0) for i in self.cols]\n",
    "        \n",
    "        # If effects wasn't a listlike structure, generate effects according to specifications\n",
    "        if self.effects is None or type(self.effects) == str:\n",
    "            self.effects = self.random_interaction(self.important_variables, functions=self.target_functions)\n",
    "\n",
    "        self.bucket_importances = {}\n",
    "        self.bucket_importances['constant'] = [1 if var in self.important_variables else 0 for var in self.cols]\n",
    "        self.bucket_importances['scaled'] = [max(self.effects[var](0), self.effects[var](1), key=abs) if var in self.important_variables else 0 for var in self.cols]\n",
    "        \n",
    "        #not implemented yet\n",
    "        self.bucket_importances['sobol'] = [max(self.effects[var](0), self.effects[var](1), key=abs) if var in self.important_variables else 0 for var in self.cols]\n",
    "\n",
    "        self.importances = [1 if var in self.important_variables else 0 for var in self.cols]\n",
    "\n",
    "        if importance_ranking == 'constant':\n",
    "            self.importances = self.bucket_importances['constant']\n",
    "        elif importance_ranking == 'scaled':\n",
    "            self.importances = self.bucket_importances['scaled']\n",
    "        elif importance_ranking == 'sobol':\n",
    "            self.importances = self.bucket_importances['sobol']\n",
    "        else:\n",
    "            raise ValueError(\"importance_ranking must be 'constant', 'quick', or 'sobol'\")\n",
    "    \n",
    "    def random_interaction(self, interacting_variables, cols=None, functions=None, monotonic=None):\n",
    "        \"\"\"\n",
    "        Generates a pandas Series of lambda functions representing diverse interaction terms for binary data.\n",
    "        Each function corresponds to a column in 'cols'.\n",
    "\n",
    "        Note that this function is meant to provide a list of functions that will all be applied and then summed\n",
    "        in order to get the value of a single column in the generated data. Use the generate_interactions\n",
    "        function to generate all interactions for a generated dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - cols (list or Series): List of all column indices in the dataset\n",
    "        - interacting_variables (list or Series): List of column indices within 'cols' for which to\n",
    "          generate specific interaction terms based on random selections of interactions.\n",
    "        - functions (list or Series of functions): List of functions to choose from when generating interactions.\n",
    "          Should have parameters n, c, i, and sign\n",
    "\n",
    "        Returns:\n",
    "        - series of lambda functions: Each function is designed to apply a specific interaction\n",
    "          to its input, based on the type of interaction randomly assigned to its corresponding column.\n",
    "        \"\"\"\n",
    "        # Set class values if parameters None\n",
    "        cols = cols if cols is not None else self.cols\n",
    "        functions = functions if functions is not None else self.functions\n",
    "        monotonic = monotonic if monotonic is not None else self.monotonic\n",
    "\n",
    "        interaction_list = [lambda x: 0 for col in cols]\n",
    "\n",
    "        for col in interacting_variables:\n",
    "            # Generate random values\n",
    "            roll = random.choice(range(len(functions)))\n",
    "            n = random.randint(1, DataGenerator.EFFECT_EXPONENT_RANGE)\n",
    "            c = random.randint(1, DataGenerator.EFFECT_SCALE_RANGE)\n",
    "            i = random.randint(0, 1)\n",
    "            sign = random.choice([-1, 1])\n",
    "            if monotonic:\n",
    "                sign = 1\n",
    "\n",
    "            f = lambda x, roll=roll, n=n, c=c, i=i, sign=sign: functions[roll](x, sign=sign, c=c, n=n, i=i)\n",
    "\n",
    "            interaction_list[col] = f\n",
    "\n",
    "        return pd.Series(interaction_list)\n",
    "\n",
    "    def generate_interactions(self, cols=None, interaction_terms=None, important_variables=None, scale=None, distribution=None):\n",
    "        \"\"\"\n",
    "        Generates interaction terms for a dataset by selecting random samples of columns and creating interaction\n",
    "        functions for them. This function orchestrates the creation of a comprehensive dataframe of interaction\n",
    "        terms, combining both targeted columns and a subset of other columns to enrich the dataset's features with\n",
    "        interactions. Apply the generated interaction functions across a dataset for generated interaction terms\n",
    "\n",
    "        This function relies on 'random_interaction' to create specific interaction functions for each term and 'random_interactions'\n",
    "        to compile these into a dictionary format suitable for application across a dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - cols (list or Series): List of all column indices in the dataset. This list is used to randomly select columns for\n",
    "        generating interactions.\n",
    "        - interaction_terms (list or Series): List of column indices for which interaction terms are explicitly desired.\n",
    "        This list guides the focus of interaction term generation.\n",
    "        - important_variables (list or Series of int, optional): The subset of 'cols' that are actually used in calculation of target variable.\n",
    "        If not provided, defaults to using 'cols'.\n",
    "        - important_samples (int, optional): Number of samples to take from the important variables for each interaction term.\n",
    "        If not provided, defaults to one-fifth of the length of 'targets'.\n",
    "        - other_samples (int, optional): Number of samples to take from the set difference of 'cols' and 'targets' for each interaction term.\n",
    "        If not provided, defaults to one-fifth of the difference in length between 'cols' and 'targets'.\n",
    "\n",
    "        Returns:\n",
    "        - Series: A Series where each index corresponds to an index of an interaction term, and the row is a list of functions.\n",
    "        These functions, when applied, generate the interaction terms for the dataset, ready for use in further analysis or modeling.\n",
    "        \"\"\"\n",
    "        # Set class values if parameters None\n",
    "        cols = cols if cols is not None else self.cols\n",
    "        interaction_terms = interaction_terms if interaction_terms is not None else self.interaction_terms\n",
    "        important_variables = important_variables if important_variables is not None else self.important_variables\n",
    "        scale = scale if scale is not None else self.correlation_scale\n",
    "        distribution = distribution if distribution is not None else self.correlation_distribution\n",
    "\n",
    "        interactions = {}\n",
    "        rng = self.rng\n",
    "\n",
    "        # Get random columns to interact with\n",
    "        for term in interaction_terms:\n",
    "            mimicking = rng.choice(important_variables)\n",
    "\n",
    "            correlation = 0\n",
    "\n",
    "            if distribution == 'uniform':\n",
    "                correlation = rng.uniform(-scale, scale)\n",
    "            elif distribution == 'normal':\n",
    "                correlation = rng.normal(scale=scale)\n",
    "            elif distribution == 'beta':\n",
    "                correlation = rng.beta(scale, scale)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported distribution. Choose from 'uniform' or 'normal' or 'beta'.\")\n",
    "            \n",
    "            correlation = max(-1, min(1, correlation))\n",
    "            interactions[term] = (mimicking, correlation)\n",
    "\n",
    "        return interactions\n",
    "    \n",
    "    def generate_noise(self, size, distribution=None, scale=None):\n",
    "        \"\"\"\n",
    "        Generate noise using NumPy.\n",
    "\n",
    "        Parameters:\n",
    "        - distribution: Type of distribution to generate noise from.\n",
    "                         Supported distributions: 'uniform', 'normal', 'gamma'\n",
    "                         Default is 'uniform'.\n",
    "        - scale: Scale parameter for the chosen distribution.\n",
    "                 For 'uniform', it's the range of the distribution.\n",
    "                 For 'normal', it's the standard deviation.\n",
    "                 For 'gamma', it's the shape parameter.\n",
    "                 Default is 1.0.\n",
    "\n",
    "        Returns:\n",
    "        - noise: NumPy array containing generated noise.\n",
    "        \"\"\"\n",
    "\n",
    "        distribution = self.noise_distribution if distribution is None else distribution\n",
    "        scale = self.noise_scale if scale is None else scale\n",
    "\n",
    "        rng = self.rng\n",
    "\n",
    "        if scale == 0:\n",
    "            noise = np.zeros(size)  # If scale is zero, return an array of zeros\n",
    "        elif distribution == 'uniform':\n",
    "            noise = rng.uniform(-scale, scale, size=size)\n",
    "        elif distribution == 'normal':\n",
    "            noise = rng.normal(scale=scale, size=size)\n",
    "        elif distribution == 'gamma':\n",
    "            noise = rng.gamma(scale, size=size)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distribution. Choose from 'uniform', 'normal', or 'gamma'.\")\n",
    "\n",
    "        return noise\n",
    "    \n",
    "    def predict(self, X, effects=None, target=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        X = X.astype(int)\n",
    "\n",
    "        effects = effects if effects is not None else self.effects\n",
    "        target = target if target is not None else self.target\n",
    "\n",
    "        return sum(X[col].apply(effects[col]) for col in X.columns if col != target)\n",
    "    \n",
    "    def generate_data(self, num_rows=None, cols=None, frequencies=None, effects=None, interactions=None, target=None, intercept=None, noise_distribution=None, noise_scale=None):\n",
    "        \"\"\"\n",
    "        Generates a complex dataset with binary columns, interaction terms, noise, and a target variable.\n",
    "        This function allows for the simulation of datasets with specified properties, including\n",
    "        predefined effects for certain columns, variable frequencies, interactions between variables,\n",
    "        and a range of noise to simulate real-world data variance.\n",
    "\n",
    "        Parameters:\n",
    "        - num_rows (int): Number of rows (samples) in the generated dataset.\n",
    "        - cols (list or Series): List of column indices that will be included in the dataset.\n",
    "        - effects (dict, optional): Dictionary where keys are column indices and values are functions\n",
    "        that define how each column influences the target variable.\n",
    "        - frequencies (dict, optional): Dictionary specifying the frequency (probability) of 1s for each binary column.\n",
    "        Keys are column indices, and values are probabilities (0 to 1).\n",
    "        - interactions (dict or Series, optional): Dictionary specifying interactions between columns.\n",
    "        Keys are column indices, and values are lists of functions representing the interaction effects.\n",
    "        - target (str, optional): Name of the target column.\n",
    "        - intercept (float, optional): The intercept (bias) term added to the target variable calculation.\n",
    "        It can shift the target variable up or down.\n",
    "        - noise (float, optional): Bound for the uniform distribution from which noise is generated (from -1 * noise to noise)\n",
    "\n",
    "        Returns:\n",
    "        - DataFrame: A pandas DataFrame containing the generated dataset. Includes binary columns as specified by 'cols',\n",
    "        interaction terms as specified by 'interactions', and a target column influenced by 'effects', 'intercepts', and added noise.\n",
    "\n",
    "        This function first generates binary data for each column based on specified frequencies.\n",
    "        Then, it applies interaction functions to create complex relationships between variables.\n",
    "        Noise is uniformly added to introduce variability.\n",
    "        The target variable is calculated by summing the effects of important columns, interactions, and noise, adjusted by the intercept.\n",
    "        This allows for the creation of datasets that can simulate various real-world scenarios, useful for testing machine learning models and data analysis techniques.\n",
    "        \"\"\"\n",
    "        num_rows = num_rows if num_rows is not None else self.num_rows\n",
    "        cols = cols if cols is not None else self.cols\n",
    "        frequencies = frequencies if frequencies is not None else self.frequencies\n",
    "        effects = effects if effects is not None else self.effects\n",
    "        interactions = interactions if interactions is not None else self.interactions\n",
    "        target = target if target is not None else self.target\n",
    "        intercept = intercept if intercept is not None else self.intercept\n",
    "        noise_scale = noise_scale if noise_scale is not None else self.noise_scale\n",
    "        noise_distribution = noise_distribution if noise_distribution is not None else self.noise_distribution\n",
    "\n",
    "        rng = self.rng\n",
    "        data = {}\n",
    "\n",
    "        # Generate data for each column\n",
    "        for col in cols:\n",
    "            freq = frequencies[col]\n",
    "            data[col] = rng.choice([0, 1], size=num_rows, p=[1-freq, freq])\n",
    "            \n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Generate interactions\n",
    "        for col in interactions.keys():\n",
    "            mimicking, correlation = interactions[col]\n",
    "\n",
    "            df[col] = df.apply(lambda row: (1 - row[mimicking]) if (random.uniform(0, 1) < abs(correlation) and correlation < 0) \n",
    "                    else (row[mimicking] if (random.uniform(0, 1) < abs(correlation) and correlation > 0) \n",
    "                        else row[col]), \n",
    "            axis=1)\n",
    "            df[col] = df[col].astype(int)\n",
    "        \n",
    "        df = df.copy()\n",
    "\n",
    "        important_sum = self.predict(df)\n",
    "        \n",
    "        noise = self.generate_noise(scale=noise_scale * np.max(np.abs(important_sum)), distribution=noise_distribution, size=df.shape[0])\n",
    "\n",
    "        # Generate target based on important cols, interactions, and non-linear effects\n",
    "        df[target] = important_sum + noise + intercept\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /home/kh/.local/lib/python3.8/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/kh/.local/lib/python3.8/site-packages (from scipy) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'constant': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " 'scaled': [1,\n",
       "  1,\n",
       "  0,\n",
       "  -1.4953487812212205,\n",
       "  0.7924812503605781,\n",
       "  -1,\n",
       "  0,\n",
       "  -0.00032,\n",
       "  0.3868528072345416,\n",
       "  2.584962500721156],\n",
       " 'sobol': [1,\n",
       "  1,\n",
       "  0,\n",
       "  -1.4953487812212205,\n",
       "  0.7924812503605781,\n",
       "  -1,\n",
       "  0,\n",
       "  -0.00032,\n",
       "  0.3868528072345416,\n",
       "  2.584962500721156]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from scipy.stats import sobol_indices, uniform\n",
    "dgp = DataGenerator(num_cols=10, num_rows=10, num_important=10, effects='all', num_interaction_terms=2, correlation_scale=0.5, noise_scale=0.1)\n",
    "data = dgp.generate_data()\n",
    "dgp.bucket_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variable_importance.dgp import DataGenerator\n",
    "\n",
    "try:\n",
    "    for i in range(1000):\n",
    "        dgp = DataGenerator(num_cols=100, num_rows=10, num_important=5, effects='all', num_interaction_terms=20, correlation_range=[-1, -0.9])\n",
    "        data = dgp.generate_data()\n",
    "except Exception as e:\n",
    "    print(\"exception occurred\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "from variable_importance.dgp import DataGenerator\n",
    "\n",
    "class TestNoiseGeneration(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.num_cols = 10\n",
    "        self.generator = DataGenerator(num_cols=self.num_cols, num_rows=100)\n",
    "\n",
    "    def test_uniform_noise(self):\n",
    "        noise = self.generator.generate_noise(size=1000, distribution='uniform', scale=5)\n",
    "        self.assertEqual(len(noise), 1000)\n",
    "        self.assertTrue(np.all(noise >= -5) and np.all(noise <= 5))\n",
    "\n",
    "    def test_normal_noise(self):\n",
    "        noise = self.generator.generate_noise(size=1000, distribution='normal', scale=2)\n",
    "        self.assertEqual(len(noise), 1000)\n",
    "        self.assertTrue(np.mean(noise) < 0.5)  # Assuming mean is approximately 0\n",
    "        self.assertTrue(np.std(noise) > 1.5 and np.std(noise) < 2.5)  # Assuming std deviation is approximately 2\n",
    "\n",
    "    def test_gamma_noise(self):\n",
    "        noise = self.generator.generate_noise(size=1000, distribution='gamma', scale=2)\n",
    "        self.assertEqual(len(noise), 1000)\n",
    "        self.assertTrue(np.all(noise >= 0))  # Gamma distribution is always non-negative\n",
    "        self.assertTrue(np.mean(noise) > 0)\n",
    "\n",
    "    def test_unsupported_distribution(self):\n",
    "        with self.assertRaises(ValueError):\n",
    "            self.generator.generate_noise(size=100, distribution='unsupported', scale=1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class TestDataGenerator(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.generator = DataGenerator(num_cols=10, num_rows=100, num_important=3, noise_scale=1, noise_distribution='normal')\n",
    "\n",
    "    def test_initialization(self):\n",
    "        \"\"\"Test the initialization and settings of DataGenerator parameters.\"\"\"\n",
    "        self.assertEqual(self.generator.num_cols, 10)\n",
    "        self.assertEqual(self.generator.num_rows, 100)\n",
    "        self.assertEqual(self.generator.num_important, 3)\n",
    "        self.assertIsNotNone(self.generator.frequencies)\n",
    "        self.assertEqual(len(self.generator.frequencies), 10)\n",
    "\n",
    "    def test_noise_generation(self):\n",
    "        \"\"\"Test noise generation for uniform and normal distributions.\"\"\"\n",
    "        noise_uniform = self.generator.generate_noise(100, 'uniform', 1)\n",
    "        noise_normal = self.generator.generate_noise(100, 'normal', 1)\n",
    "        self.assertEqual(len(noise_uniform), 100)\n",
    "        self.assertEqual(len(noise_normal), 100)\n",
    "        self.assertTrue(np.all(noise_uniform >= -1) and np.all(noise_uniform <= 1))\n",
    "        # Check that the noise is normally distributed by checking the mean is close to 0\n",
    "        self.assertTrue(abs(np.mean(noise_normal)) < 0.5)\n",
    "\n",
    "    def test_interaction_generation(self):\n",
    "        \"\"\"Test the generation of interaction terms.\"\"\"\n",
    "        interactions = self.generator.generate_interactions()\n",
    "        self.assertIsInstance(interactions, dict)\n",
    "        self.assertTrue(all(isinstance(k, tuple) and len(k) == 2 for k in interactions.values()))\n",
    "\n",
    "    def test_data_generation(self):\n",
    "        \"\"\"Test the overall data generation process.\"\"\"\n",
    "        df = self.generator.generate_data()\n",
    "        self.assertIsInstance(df, pd.DataFrame)\n",
    "        self.assertEqual(df.shape, (100, 11))  # 10 features + 1 target\n",
    "        self.assertTrue('target' in df.columns)\n",
    "\n",
    "    def test_effects_application(self):\n",
    "        \"\"\"Test that effects are applied correctly.\"\"\"\n",
    "        self.generator.effects = {i: (lambda x: x * 2) for i in range(10)}\n",
    "        df = self.generator.generate_data()\n",
    "        for col in range(10):\n",
    "            with self.subTest(column=col):\n",
    "                self.assertTrue((df[col] * 2).equals(df[col] * df[col].apply(self.generator.effects[col])))\n",
    "\n",
    "# Running the tests in Jupyter Notebook\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
