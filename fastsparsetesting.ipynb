{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from warnings import simplefilter\n",
    "from variable_importance.dgp import DataGenerator\n",
    "from variable_importance.variable_importance_scoring import importance_score, cross_validation_scores\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fastsparsegams\n",
    "\n",
    "class FastSparseSklearn(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_support_size, tol=1e-8, lambda_0=0.025, gamma=0):\n",
    "        # self.data = data \n",
    "        # self.labels = labels\n",
    "        # self.data = data.to_numpy() if not isinstance(data, np.ndarray) else data\n",
    "        # self.labels = labels.to_numpy() if not isinstance(labels, np.ndarray) else labels\n",
    "        # self.data = self.transform(data)\n",
    "        # self.num_features = np.shape(data)[1]\n",
    "        self.max_support_size = max_support_size\n",
    "        # self.labels = self.labels[0].T\n",
    "        self.tol = tol\n",
    "        self.lambda_0 = lambda_0\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def transform(self, data):\n",
    "        data = data.to_numpy() if not isinstance(data, np.ndarray) else data\n",
    "        data = data.astype(float)\n",
    "        return data\n",
    "    \n",
    "    def fit(self, data, labels):\n",
    "        data = self.transform(data)\n",
    "        labels = self.transform(labels)\n",
    "        self.model = fastsparsegams.fit(data, labels, penalty=\"L0\", max_support_size=self.max_support_size, algorithm = \"CDPSI\")\n",
    "        self.feature_importances_ = self.model.coeff(lambda_0=self.lambda_0, gamma=self.gamma).toarray()\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.transform(X)\n",
    "        return self.model.predict(X, lambda_0=self.lambda_0, gamma=self.gamma)\n",
    "        \n",
    "    def feature_importances(self):\n",
    "        print(self.model)\n",
    "        sz = len(self.model.lambda_0[0])\n",
    "        lambda0 = self.model.lambda_0[0][sz-1]\n",
    "        print(self.model.coeff(lambda_0=lambda0))\n",
    "        best = np.where(np.abs(self.model.coeff(lambda_0=lambda0).toarray()) > self.tol)[0]\n",
    "        print(best)\n",
    "        importances = [0] * self.num_features\n",
    "        for ind in best:\n",
    "            importances[ind-1] = self.model.coeff(lambda_0=lambda0).toarray()[ind]\n",
    "        return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_support_size\": [5, 10, 15, 20, 25],\n",
    "    \"tol\": [1e-9, 1e-8, 1e-7, 1e-6],\n",
    "    \"lambda_0\": [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "dgp = DataGenerator(num_cols=10, num_rows=20, num_important=3, num_interaction_terms=0, effects='linear', noise_scale=0.5)\n",
    "dataset = dgp.generate_data()\n",
    "\n",
    "X = dataset.drop([\"target\"], axis=1)\n",
    "y = dataset[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = FastSparseSklearn(20)\n",
    "\n",
    "rscv = RandomizedSearchCV(fs, param_grid, scoring='r2', verbose=0, cv=3, n_iter=10, n_jobs=2)\n",
    "rscv.fit(X_train, y_train)\n",
    "best_model = rscv.best_estimator_\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "r2_score(y_test, y_test_pred)\n",
    "best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgp = DataGenerator(num_cols=10, num_rows=20, num_important=3, num_interaction_terms=0, effects='linear', noise_scale=0.5)\n",
    "dataset = dgp.generate_data()\n",
    "\n",
    "X = dataset.drop([\"target\"], axis=1)\n",
    "y = dataset[\"target\"]\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)\n",
    "model = fastsparsegams.fit(X, y, penalty=\"L0\", max_support_size=20, algorithm=\"CDPSI\")\n",
    "y_pred = model.predict(x=X, lambda_0=0.032715, gamma=0)\n",
    "y_pred.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
